name: PCM

params:
  _target_: models.segmentation.SegmentationHead
  in_channels: 5
  num_classes: ${dataset.params.num_classes}
  embedding_size: 64 # multiply embed_dim by factors in dim_expansion
  hidden_dim: 256 
  encoder: 
    _target_: models.PCM.PCM.PointMambaEncoder
    in_channels: ${..in_channels}
    embed_dim: 64
    mamba_blocks: [1]
    # mamba_blocks: [3]
    dim_expansion: [1]
    pre_blocks: [1]
    pos_blocks: [0]
    k_neighbors: [1]
    reducers: [2]

    # mamba_pos: True
    # use_order_prompt: True
    # prompt_num_per_order: 6

    mamba_layers_orders: ["xyz", "yxz", "zyx"] 
    parallel_multihead: True
    # set to false for multiple mamba_blocks
    # parallel_multihead: False


optimizer:
  _target_: torch.optim.Adam
  lr: 0.001
  weight_decay: 0.0

warmup_epochs: 1

batch_size: 1

# scheduler: cosine
scheduler: step
step_size: 150
gamma: 0.5

